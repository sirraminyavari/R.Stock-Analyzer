{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>class</th>\n",
       "      <th>symbol</th>\n",
       "      <th>total_roc_trend_60_negative</th>\n",
       "      <th>total_roc_trend_60_positive</th>\n",
       "      <th>total_roc_trend_60_level</th>\n",
       "      <th>total_roc_trend_60_returns</th>\n",
       "      <th>total_roc_trend_20_negative</th>\n",
       "      <th>total_roc_trend_20_positive</th>\n",
       "      <th>total_roc_trend_20_level</th>\n",
       "      <th>...</th>\n",
       "      <th>atr_14_7</th>\n",
       "      <th>atr_14_8</th>\n",
       "      <th>atr_14_9</th>\n",
       "      <th>atr_14_10</th>\n",
       "      <th>atr_14_11</th>\n",
       "      <th>atr_14_12</th>\n",
       "      <th>atr_14_13</th>\n",
       "      <th>atr_14_14</th>\n",
       "      <th>last_idle_days</th>\n",
       "      <th>idle_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>البرز</td>\n",
       "      <td>0.126429</td>\n",
       "      <td>0.490495</td>\n",
       "      <td>0.742242</td>\n",
       "      <td>13</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>0.232261</td>\n",
       "      <td>0.777949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>-0.044931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>دسبحان</td>\n",
       "      <td>0.206821</td>\n",
       "      <td>1.003983</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.532577</td>\n",
       "      <td>0.986059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.075927</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>دپارس</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.349337</td>\n",
       "      <td>0.687274</td>\n",
       "      <td>24</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.185553</td>\n",
       "      <td>0.881331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.087933</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>دکوثر</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.428227</td>\n",
       "      <td>0.518419</td>\n",
       "      <td>26</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>0.117207</td>\n",
       "      <td>0.544562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022558</td>\n",
       "      <td>-0.010902</td>\n",
       "      <td>-0.005782</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>-0.006570</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>سفارس</td>\n",
       "      <td>0.218341</td>\n",
       "      <td>0.816629</td>\n",
       "      <td>0.732631</td>\n",
       "      <td>19</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.389881</td>\n",
       "      <td>0.959604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005884</td>\n",
       "      <td>0.031591</td>\n",
       "      <td>0.063304</td>\n",
       "      <td>-0.004356</td>\n",
       "      <td>-0.007517</td>\n",
       "      <td>-0.020903</td>\n",
       "      <td>-0.013766</td>\n",
       "      <td>0.034616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  class  symbol  total_roc_trend_60_negative  \\\n",
       "0      19      0   البرز                     0.126429   \n",
       "1       8      2  دسبحان                     0.206821   \n",
       "2      38      1   دپارس                     0.109247   \n",
       "3      45      0   دکوثر                     0.206226   \n",
       "4       9      2   سفارس                     0.218341   \n",
       "\n",
       "   total_roc_trend_60_positive  total_roc_trend_60_level  \\\n",
       "0                     0.490495                  0.742242   \n",
       "1                     1.003983                  0.794000   \n",
       "2                     0.349337                  0.687274   \n",
       "3                     0.428227                  0.518419   \n",
       "4                     0.816629                  0.732631   \n",
       "\n",
       "   total_roc_trend_60_returns  total_roc_trend_20_negative  \\\n",
       "0                          13                     0.051574   \n",
       "1                          18                     0.007425   \n",
       "2                          24                     0.022020   \n",
       "3                          26                     0.053380   \n",
       "4                          19                     0.015750   \n",
       "\n",
       "   total_roc_trend_20_positive  total_roc_trend_20_level  ...  atr_14_7  \\\n",
       "0                     0.232261                  0.777949  ...  0.006767   \n",
       "1                     0.532577                  0.986059  ...  0.004689   \n",
       "2                     0.185553                  0.881331  ...  0.042524   \n",
       "3                     0.117207                  0.544562  ...  0.022558   \n",
       "4                     0.389881                  0.959604  ... -0.005884   \n",
       "\n",
       "   atr_14_8  atr_14_9  atr_14_10  atr_14_11  atr_14_12  atr_14_13  atr_14_14  \\\n",
       "0  0.010990  0.008281   0.040443   0.005580   0.002960  -0.000645  -0.044931   \n",
       "1  0.075927  0.005482   0.004319   0.003617   0.001554  -0.000754   0.022577   \n",
       "2  0.044743  0.005929   0.000039   0.087933   0.004962   0.002055  -0.001321   \n",
       "3 -0.010902 -0.005782   0.007787  -0.006570   0.045846   0.006888   0.023999   \n",
       "4  0.031591  0.063304  -0.004356  -0.007517  -0.020903  -0.013766   0.034616   \n",
       "\n",
       "   last_idle_days  idle_days  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          3  \n",
       "4               0          0  \n",
       "\n",
       "[5 rows x 629 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_COUNT = \"3\"\n",
    "FILE_COUNTER = \"9\"\n",
    "#C3_P3, C2_P4 works like a charm\n",
    "\n",
    "#stock_dataset  = pd.read_csv('stock_c' + CLASS_COUNT + '_p' + PARAMS_COUNT + '.csv')\n",
    "#real_dataframe  = pd.read_csv('stock_real_p' + PARAMS_COUNT + '.csv')\n",
    "\n",
    "stock_dataset  = pd.read_csv('stock_c' + CLASS_COUNT + '_' + FILE_COUNTER + '.csv')\n",
    "real_dataframe  = pd.read_csv('stock_real_' + FILE_COUNTER + '.csv')\n",
    "\n",
    "stock_dataset = stock_dataset.dropna(axis='rows')\n",
    "real_dataframe = real_dataframe.dropna(axis='rows')\n",
    "\n",
    "stock_dataset.head() #visualized top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dataset = stock_dataset.to_numpy()\n",
    "real_dataset = real_dataframe.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_inputs = real_dataset[:,3:]\n",
    "inputs = stock_dataset[:,3:]\n",
    "targets = stock_dataset[:,1]\n",
    "\n",
    "class_size = np.amax(targets, axis = 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "\n",
    "scaled_inputs = scaler.transform(inputs)\n",
    "real_inputs = scaler.transform(real_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "useKFold = samples_count < 4000\n",
    "\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = 0 if useKFold else int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = tf.convert_to_tensor(train_inputs, np.float32)\n",
    "train_targets = tf.convert_to_tensor(train_targets, np.float32)\n",
    "\n",
    "validation_inputs = tf.convert_to_tensor(validation_inputs, np.float32)\n",
    "validation_targets = tf.convert_to_tensor(validation_targets, np.float32)\n",
    "\n",
    "test_inputs = tf.convert_to_tensor(test_inputs, np.float32)\n",
    "test_targets = tf.convert_to_tensor(test_targets, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_inputs.shape[1]\n",
    "output_size = class_size\n",
    "hidden_layer_size = 1800\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.1024 - accuracy: 0.3838\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 1.0099 - accuracy: 0.5279\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8544 - accuracy: 0.6338\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.7041 - accuracy: 0.7082\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.5631 - accuracy: 0.7835\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.4370 - accuracy: 0.8476\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3196 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.2204 - accuracy: 0.9405\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.1629 - accuracy: 0.9684\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1323 - accuracy: 0.9647\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.8966 - accuracy: 0.3810\n",
      "\n",
      "Test loss: 1.90. Test accuracy: 38.10%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.3060 - accuracy: 0.3690\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9765 - accuracy: 0.5093\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8442 - accuracy: 0.6292\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.7234 - accuracy: 0.7045\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.5941 - accuracy: 0.7723\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.4504 - accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3218 - accuracy: 0.9154\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.2446 - accuracy: 0.9359\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.1690 - accuracy: 0.9610\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1307 - accuracy: 0.9675\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.5754 - accuracy: 0.4524\n",
      "\n",
      "Test loss: 1.58. Test accuracy: 45.24%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.6397 - accuracy: 0.3783\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 1.0106 - accuracy: 0.4740\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8937 - accuracy: 0.6199\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.7592 - accuracy: 0.6747\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.6500 - accuracy: 0.7416\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.4926 - accuracy: 0.8318\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3915 - accuracy: 0.8615\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.3052 - accuracy: 0.9164\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.2009 - accuracy: 0.9507\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1826 - accuracy: 0.9424\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.8653 - accuracy: 0.4524\n",
      "\n",
      "Test loss: 1.87. Test accuracy: 45.24%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.3071 - accuracy: 0.3857\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9760 - accuracy: 0.5400\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8655 - accuracy: 0.6236\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.7300 - accuracy: 0.6868\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.6035 - accuracy: 0.7723\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.5055 - accuracy: 0.8113\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3744 - accuracy: 0.8922\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.2705 - accuracy: 0.9182\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.1895 - accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1442 - accuracy: 0.9582\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 2.4131 - accuracy: 0.4524\n",
      "\n",
      "Test loss: 2.41. Test accuracy: 45.24%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.3862 - accuracy: 0.3606\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9815 - accuracy: 0.5353\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8173 - accuracy: 0.6664\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.6675 - accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.5280 - accuracy: 0.8132\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.3938 - accuracy: 0.8838\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3070 - accuracy: 0.9136\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.1980 - accuracy: 0.9591\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.1738 - accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1139 - accuracy: 0.9740\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.8718 - accuracy: 0.4762\n",
      "\n",
      "Test loss: 1.87. Test accuracy: 47.62%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 2.2298 - accuracy: 0.3717\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9807 - accuracy: 0.5074\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8301 - accuracy: 0.6366\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.6963 - accuracy: 0.6914\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.6086 - accuracy: 0.7361\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.4831 - accuracy: 0.8225\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.3694 - accuracy: 0.8578\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.2974 - accuracy: 0.9108\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.2695 - accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.2149 - accuracy: 0.9368\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.6746 - accuracy: 0.4286\n",
      "\n",
      "Test loss: 1.67. Test accuracy: 42.86%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 1.9479 - accuracy: 0.3773\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9818 - accuracy: 0.5214\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8422 - accuracy: 0.6413\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.6701 - accuracy: 0.7351\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.5330 - accuracy: 0.7928\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.3954 - accuracy: 0.8699\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.2647 - accuracy: 0.9284\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.1849 - accuracy: 0.9582\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.1466 - accuracy: 0.9684\n",
      "Epoch 10/10\n",
      "1076/1076 - 0s - loss: 0.1112 - accuracy: 0.9740\n",
      "42/42 [==============================] - 0s 2ms/sample - loss: 1.7145 - accuracy: 0.5476\n",
      "\n",
      "Test loss: 1.71. Test accuracy: 54.76%\n",
      "\n",
      "Train on 1076 samples\n",
      "Epoch 1/10\n",
      "1076/1076 - 1s - loss: 1.8796 - accuracy: 0.3764\n",
      "Epoch 2/10\n",
      "1076/1076 - 0s - loss: 0.9441 - accuracy: 0.5418\n",
      "Epoch 3/10\n",
      "1076/1076 - 0s - loss: 0.8014 - accuracy: 0.6636\n",
      "Epoch 4/10\n",
      "1076/1076 - 0s - loss: 0.6268 - accuracy: 0.7556\n",
      "Epoch 5/10\n",
      "1076/1076 - 0s - loss: 0.4800 - accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "1076/1076 - 0s - loss: 0.3503 - accuracy: 0.8913\n",
      "Epoch 7/10\n",
      "1076/1076 - 0s - loss: 0.2338 - accuracy: 0.9470\n",
      "Epoch 8/10\n",
      "1076/1076 - 0s - loss: 0.1270 - accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1076/1076 - 0s - loss: 0.0854 - accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "folds_count = int(samples_count / 50)\n",
    "\n",
    "fold_counter = 0\n",
    "fold_estimate_loss = [None] * folds_count if useKFold else 1\n",
    "fold_estimate_accuracy = [None] * folds_count if useKFold else 1\n",
    "\n",
    "if useKFold:\n",
    "    for train_index, test_index in KFold(folds_count).split(train_inputs):\n",
    "        x_train, x_test = tf.gather(train_inputs, train_index), tf.gather(train_inputs, test_index)\n",
    "        y_train, y_test = tf.gather(train_targets, train_index), tf.gather(train_targets, test_index)\n",
    "\n",
    "        model = create_model()\n",
    "    \n",
    "        model.fit(x_train, \n",
    "                  y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = max_epochs, \n",
    "                  verbose = 2)\n",
    "        \n",
    "        test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "        fold_estimate_loss[fold_counter] = test_loss\n",
    "        fold_estimate_accuracy[fold_counter] = test_accuracy * 100\n",
    "        fold_counter += 1\n",
    "        \n",
    "        print('')\n",
    "        print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy * 100))\n",
    "        print('')\n",
    "else:\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience = 20)\n",
    "    model = create_model()\n",
    "    \n",
    "    model.fit(train_inputs, \n",
    "              train_targets,\n",
    "              batch_size = batch_size,\n",
    "              epochs = max_epochs, \n",
    "              callbacks = [early_stopping],\n",
    "              validation_data = (validation_inputs, validation_targets), \n",
    "              verbose = 2)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useKFold :\n",
    "    plt.hist(fold_estimate_accuracy, density=True)  # `density=False` would make counts\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Accuracy');\n",
    "else :\n",
    "    print('')\n",
    "    print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy * 100.0))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(real_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_dataframe = real_dataframe.drop(columns = ['target', 'class'])\n",
    "\n",
    "for i in range(predictions.shape[1]):\n",
    "    real_dataframe.insert(i, \"pred_class_\" + str(i), predictions[:,i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((predictions.shape[0], 1))\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    cls = 0\n",
    "    lastValue = 0\n",
    "    for j in range(predictions.shape[1]):\n",
    "        if predictions[i, j] > lastValue :\n",
    "            lastValue = predictions[i, j]\n",
    "            cls = j\n",
    "    pred[i, 0] = cls\n",
    "    \n",
    "real_dataframe.insert(predictions.shape[1], \"predicted\", pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataframe.to_csv('stock_pred_c' + CLASS_COUNT + '_' + FILE_COUNTER + '.csv', encoding = 'utf-8-sig', index = False)\n",
    "#real_dataframe.to_csv('stock_pred_c' + CLASS_COUNT + '_p' + PARAMS_COUNT + '.csv', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3-TF2.0)",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
